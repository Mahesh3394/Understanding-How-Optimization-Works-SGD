{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "outputs": [],
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8W2fg1cyGdX",
        "outputId": "8c564112-2069-4b40-c5a7-2fed9f9e1fce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "outputs": [],
      "source": [
        "#please don't change random state\n",
        "# you need not standardize the data as it is already standardized\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DR_YMBsyOci",
        "outputId": "be0b9d58-9320-41e3-c490-ebcb9c70c742"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stDGbqPg4gJG",
        "outputId": "f4ba433d-0175-48c2-d708-84d8653b9c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1.827818   -0.45810992  0.47407375 -2.17856544 -1.16453085 -0.59906384\n",
            "  2.24400146  0.2664526  -1.59252721 -2.3705834  -1.14068014 -1.83108915\n",
            " -0.32123197  0.31287131 -1.494433  ]\n"
          ]
        }
      ],
      "source": [
        "print(X_train[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HpvTwDHyQQy",
        "outputId": "62022585-06ae-426d-896a-a88126c8e34e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
              "              random_state=15, verbose=2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYaVyQ2lyXcr",
        "outputId": "fb4a94f1-a913-4b6f-f467-968e0ad57986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.14 seconds.\n",
            "Convergence after 10 epochs took 0.14 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
              "              random_state=15, verbose=2)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.fit(X_train,y_train) # fitting our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAfkVI6GyaRO",
        "outputId": "9024bfc0-020f-4704-b7cf-a4595554ae34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(row_vector):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights as 1d array consisting of all zeros similar to the dimensions of row_vector\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "\n",
        "    w = np.zeros_like(row_vector)\n",
        "    b = 0\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7I6uWBRsKc4",
        "outputId": "62e40177-1aa5-40a4-b4cd-35d2048349fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(15,)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))\n",
        "w.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "\n",
        "def sigmoid(z):\n",
        "    sig = 1 / (1 + math.exp(-z))\n",
        "    return sig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "outputs": [],
      "source": [
        "def logloss(y_true,y_pred):\n",
        "    # you have been given two arrays y_true and y_pred and you have to calculate the logloss\n",
        "    #while dealing with numpy arrays you can use vectorized operations for quicker calculations as compared to using loops\n",
        "    #https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html\n",
        "    #https://www.geeksforgeeks.org/vectorized-operations-in-numpy/\n",
        "    #write your code here\n",
        "    final = 0\n",
        "    for i in range(len(y_true)):\n",
        "      loss =((y_true[i]*math.log10(y_pred[i] ))+((1-y_true[i])*(math.log10(1-y_pred[i]))))\n",
        "      final+=loss\n",
        "    loss = (-1*(final/len(y_true)))\n",
        "    \n",
        "    return loss\n",
        "\n",
        "true=np.array([1,1,0,1,0])\n",
        "pred=np.array([0.9,0.8,0.1,0.8,0.2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzttjvBFCuQ5",
        "outputId": "1cb9319b-3c87-461f-eafd-924de460c1cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#round off the value to 8 values\n",
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(np.round(loss,6)==0.076449)\n",
        "  return True\n",
        "true=np.array([1,1,0,1,0])\n",
        "pred=np.array([0.9,0.8,0.1,0.8,0.2])\n",
        "grader_logloss(true,pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "outputs": [],
      "source": [
        "\n",
        "#make sure that the sigmoid function returns a scalar value, you can use dot function operation\n",
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    \n",
        "    dw= (x * (y-sigmoid(np.dot(w,x)+b))) -((alpha * w)/N)\n",
        "\n",
        "    \n",
        "    return dw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "outputs": [],
      "source": [
        "#sb should be a scalar value\n",
        "def gradient_db(x,y,w,b):\n",
        "     '''In this function, we will compute gradient w.r.to b '''\n",
        "     db = (y-sigmoid(np.dot(w,x)+b))\n",
        "        \n",
        "     return db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PfGwwgL69QLd"
      },
      "outputs": [],
      "source": [
        "# prediction function used to compute predicted_y given the dataset X\n",
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        predict.append(sigmoid(z))\n",
        "    return np.array(predict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "outputs": [],
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    #Here eta0 is learning rate\n",
        "    #implement the code as follows\n",
        "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "    dim=X_train[0] \n",
        "    w,b = initialize_weights(dim)\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    for i in range(epochs):\n",
        "      for j in range(len(X_train)):\n",
        "          grad_dw = gradient_dw(X_train[j],y_train[j],w,b,eta0,N)\n",
        "          grad_db=gradient_db(X_train[j],y_train[j],w,b)\n",
        "          w = w + (alpha*grad_dw)\n",
        "          b = b + (alpha*grad_db)\n",
        "      y_pred_train = pred(w,b, X_train)\n",
        "      y_pred_test = pred(w,b, X_train)\n",
        "      tr_loss = logloss(y_train,y_pred_train)\n",
        "      te_loss = logloss(y_train,y_pred_test)\n",
        "      train_loss.append(tr_loss)\n",
        "      test_loss.append(te_loss)\n",
        "\n",
        "\n",
        "    return w,b,train_loss,test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sUquz7LFEZ6E"
      },
      "outputs": [],
      "source": [
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs=20\n",
        "w,b,train_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAfXsKwu9QLe",
        "outputId": "76218223-d551-44fd-bb81-04c204bc7d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-4.29394713e-01  1.92911531e-01 -1.48319226e-01  3.38095811e-01\n",
            " -2.20731189e-01  5.69669865e-01 -4.45186056e-01 -9.00099226e-02\n",
            "  2.21598219e-01  1.73588003e-01  1.98538391e-01 -4.13172177e-04\n",
            " -8.11250040e-02  3.39070544e-01  2.29369069e-02]\n",
            "-0.8897519322788823\n"
          ]
        }
      ],
      "source": [
        "#print thr value of weights w and bias b\n",
        "print(w)\n",
        "print(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2DFR4ZT9QLe",
        "outputId": "a783eef1-1b92-4938-f18e-79da9d033dcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " array([-0.8531383]))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "\n",
        "clf.coef_,clf.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot your train and test loss vs epochs </font>\n",
        "\n",
        "plot epoch number on X-axis and loss on Y-axis and make sure that the curve is converging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1O6GrRt7UeCJ",
        "outputId": "620a2094-f4b3-4dd0-d497-13197d636077"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = range(1,21)\n",
        "\n",
        "plt.plot(x, test_loss, label='Test Loss')\n",
        "plt.scatter(x, test_loss)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Logistic Regression\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "7_Custom_SGD_Assignment_LR_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
